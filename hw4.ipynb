{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mustafa YetiÅŸir\n",
    "10/Jan/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucas Kanade optical flow algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def video_to_numpy(path: str) -> np.ndarray:\n",
    "    \"\"\" Convert the video frames into a numpy array\n",
    "\n",
    "    Args:\n",
    "        path (str): path of the video\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 3D numpy array of shape (T, H, W)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frames = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    while ret:\n",
    "        grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr = grayFrame[::3, ::3]\n",
    "        frames.append(img_arr)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "    return np.stack(frames).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "from previous_homework import sobel_horizontal, sobel_vertical, gaussian_filter\n",
    "\n",
    "\n",
    "WINDOW_SIZE = 3  # Determine a value\n",
    "THRESHOLD = 0.8 # Determine a value\n",
    "\n",
    "image_sequence = video_to_numpy(\"video.mp4\")\n",
    "u_sequence = np.zeros(image_sequence.shape, dtype=np.float32)\n",
    "v_sequence = np.zeros(image_sequence.shape, dtype=np.float32)\n",
    "\n",
    "\n",
    "def derivatives(img: np.ndarray, next_img: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\" Calculate derivative images.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): 2D gray video frame of shape (H, W)\n",
    "        next_img (np.ndarray): 2D next gray video frame of shape (H, W)\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "            - x derivative I_x of shape (H, W)\n",
    "            - y derivative I_y of shape (H, W)\n",
    "            - temporal derivative I_t of shape (H, W)\n",
    "    \"\"\"\n",
    "    #we are calculating derivatives by using sobel operators we created for previous homeworks\n",
    "    x_derivative = sobel_horizontal(img)\n",
    "    y_derivative = sobel_vertical(img)\n",
    "    #calculating time derivative by making the subtraction below \n",
    "    time_derivative = next_img - img\n",
    "    mytuple = (x_derivative,y_derivative,time_derivative)\n",
    "    #return the tuple that has derivatives\n",
    "    return mytuple \n",
    "\n",
    "\n",
    "def lucas_kanade(x_derivative: np.ndarray,\n",
    "                 y_derivative: np.ndarray,\n",
    "                 time_derivative: np.ndarray,\n",
    "                 window_size: int,\n",
    "                 threshold: float\n",
    "                 ) -> np.ndarray:\n",
    "    \"\"\" Lucas Kanade optical flow for single frame transition\n",
    "\n",
    "    Args:\n",
    "        x_derivative (np.ndarray): x derivative I_x of shape (H, W)\n",
    "        y_derivative (np.ndarray): y derivative I_y of shape (H, W)\n",
    "        time_derivative (np.ndarray): temporal derivative I_t of shape (H, W)\n",
    "        window_size (int): Window size of W_p (square windows)\n",
    "        threshold (float): Eigen value threshold of the covariance matrix A^T A \n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: flow matrix of shape (H, W, 2) containing x and y flows.\n",
    "    \"\"\"\n",
    "\n",
    "    flow = np.zeros((x_derivative.shape[0], x_derivative.shape[1], 2))\n",
    "    #we are creating step variables so that in the for loops we don't need to think about window going outside \n",
    "    step_x_horizontal = x_derivative.shape[0] - window_size + 1\n",
    "    step_x_vertical = x_derivative.shape[1] - window_size + 1\n",
    "\n",
    "    for i in range(step_x_horizontal):\n",
    "        for j in range(step_x_vertical):\n",
    "            sub_x = x_derivative[i:i+window_size, j:j+window_size].flatten()\n",
    "            sub_y = y_derivative[i:i+window_size, j:j+window_size].flatten()\n",
    "            sub_t = time_derivative[i:i+window_size, j:j+window_size].flatten()\n",
    "            #calculating x, y and time derivatives inside the window by using window_size and derivative inputs \n",
    "            A = np.stack([sub_x, sub_y], axis=1)\n",
    "            eigen_values, _ = np.linalg.eig(A.T @ A) \n",
    "            # we are calculating the eigenvalues in order to check later if we will think about related point for flow or not\n",
    "\n",
    "            if np.max(eigen_values) < threshold:#if eigenvalues are not proper for checking flow, continue\n",
    "                continue\n",
    "\n",
    "            flow[i, j] = np.linalg.pinv(A.T @ A) @ A.T @ sub_t\n",
    "            # u = (A^T * A)^-1 * A^T * B     where A contains spatial derivatives and B contains time derivatives \n",
    "\n",
    "    return flow\n",
    "\n",
    "\n",
    "for index in range(len(image_sequence) - 1):\n",
    "\n",
    "    x_derivative, y_derivative, time_derivative = derivatives(\n",
    "        image_sequence[index], image_sequence[index + 1])\n",
    "\n",
    "    uv_values = lucas_kanade(\n",
    "        x_derivative, y_derivative, time_derivative,\n",
    "        window_size=WINDOW_SIZE, threshold=THRESHOLD)\n",
    "\n",
    "    u_sequence[index] = uv_values[:, :, 0]\n",
    "    v_sequence[index] = uv_values[:, :, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cell below to visualize your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizers.flow import FlowRenderer\n",
    "\n",
    "FlowRenderer(image_sequence,\n",
    "             u_sequence,\n",
    "             v_sequence)()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why can we not reliably compute flow for windows $\\mathcal{W}_p$ with small eigen values?\n",
    "\n",
    "The reason we are looking for high eigen values is that it is important to detect corners and choose the windows on the corners mostly. The reason behind this choosing corners is explained in the aperture problem question below, but it can be simply explained like if we want to compute the flow without being stick to only one direction we choose corners to monitor. If we choose windows with both eigen values are high, it is much more likely to choose a corner, if only one is high and other one is still small we choosed an edge and it is still not were smart to do. We want to detect edges and compute flow on those windows, and high eigen values is important for this operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain the aperture problem.\n",
    "\n",
    "The aperture problem is; if we are monitoring an image by using an aperture, the motion direction of an object in the image or some of the features in the image may be indefinite and ambiguous. \n",
    "\n",
    "If we think that we are trying to observe a rectangle and it is moving in a horizontal line, if we will look at the area of it's horizontal edge we will not be able to understand the motion. If the rectangle is moving both in a horizontal and vertical lines, we won't be seeing one of those motion ways depending on the edge we are looking at by our aperture, and think that the object is moving only on the one way. This is called the aperture problem, and in order to solve it we need to check corner points, so that we can see the move in any side. That is why we are finding features and look at those features in Lucas Kanade, we can't look at the whole image at once, but we also need to arrange our aperture wisely so we look at the chosen features.\n",
    "\n",
    "The one perfect example for this problem is the barber pole illusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are image corners well-conditioned points for optical flow? Show your answer.\n",
    "\n",
    "As I explained in the question above, corner points are good for operations like optical flow estimation or motion estimation, because in corner points are the regions with (at least) 2 different directions of the gradient. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "94e282ae4419c1d0d52f38e70a770bbc1d60958bd0d06209f3ced8f16aad6bd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
